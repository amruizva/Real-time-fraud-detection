{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # will be needed for saving preprocessing details\n",
    "import numpy as np # for data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "from sklearn.model_selection import train_test_split # will be used for data split\n",
    "from sklearn.preprocessing import LabelEncoder # for preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier # for training the algorithm\n",
    "from sklearn.ensemble import ExtraTreesClassifier # for training the algorithm\n",
    "import joblib # for saving algorithm and preprocessing objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/pplonski/datasets-for-start/master/adult/data.csv', skipinitialspace=True)\n",
    "x_cols = [c for c in df.columns if c != 'income']\n",
    "# set input matrix and target column\n",
    "X = df[x_cols]\n",
    "y = df['income']\n",
    "# show first rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split train / test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pre-processing\n",
    "In our data set, there are missing values and categorical columns. For ML algorithm training I will use the Random Forest algorithm from the sklearn package. In the current implementation it can not handle missing values and categorical columns, that's why we need to apply pre-processing algorithms.\n",
    "\n",
    "To fill missing values we will use the most frequent value in each column (there are many other filling methods, the one I select is just for example purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "train_mode = dict(X_train.mode().iloc[0])\n",
    "X_train = X_train.fillna(train_mode)\n",
    "print(train_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categoricals\n",
    "encoders = {}\n",
    "for column in ['workclass', 'education', 'marital-status',\n",
    "                'occupation', 'relationship', 'race',\n",
    "                'sex','native-country']:\n",
    "    categorical_convert = LabelEncoder()\n",
    "    X_train[column] = categorical_convert.fit_transform(X_train[column])\n",
    "    encoders[column] = categorical_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms training\n",
    "Data is ready, so we can train our Random Forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the Random Forest algorithm\n",
    "rf = RandomForestClassifier(n_estimators = 100)\n",
    "rf = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the Extra Trees algorithm\n",
    "et = ExtraTreesClassifier(n_estimators = 100)\n",
    "et = et.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, training the algorithm is easy, just 2 lines of code - much less than data reading and pre-processing. Now, let's save the algorithm that we have created. The important thing to notice is that the ML algorithm is not only the rf and et variable (with model weights), but we also need to save pre-processing variables train_mode and encoders as well. For saving, I will use joblib package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preprocessing objects and RF algorithm\n",
    "joblib.dump(train_mode, \"./train_mode.joblib\", compress=True)\n",
    "joblib.dump(encoders, \"./encoders.joblib\", compress=True)\n",
    "joblib.dump(rf, \"./random_forest.joblib\", compress=True)\n",
    "joblib.dump(et, \"./extra_trees.joblib\", compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
